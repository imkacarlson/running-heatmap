# Mobile App Testing Framework - Optimized Edition

This directory contains the comprehensive automated testing framework for the Running Heatmap mobile application, featuring advanced optimization capabilities for rapid development cycles.

## üöÄ Quick Start

**Simple optimized test execution:**
```bash
python run_tests.py                     # Run all tests with automatic optimization
python run_tests.py --fast              # Use cached artifacts when available
python run_tests.py --one-test          # Interactive single test selection
python run_tests.py --performance-report # Generate detailed performance metrics
```

**Persistent infrastructure for multiple test cycles:**
```bash
./persist_tests.sh start                # Start persistent services (emulator + Appium)
./test.sh                               # Run tests (will use persistent services automatically)
./test.sh                               # Run tests again (much faster)
./persist_tests.sh stop                 # Stop persistent services when done
```

## ‚ö° Optimization Features

### Intelligent Caching & Change Detection
- **Automatic APK build skipping** when source code unchanged
- **Data processing cache** when GPX files unchanged  
- **Smart dependency tracking** using file timestamps
- **Cache invalidation** when source/data changes detected
- **Persistent cache directories** for cross-session optimization

### Parallel Test Execution
- **Safe parallelization** with dependency analysis
- **Automatic fallback** to sequential execution if conflicts detected
- **Configurable worker limits** and timeout handling
- **Performance monitoring** with speedup calculations

### Persistent Infrastructure
- **Optional persistent mode** keeps emulator and Appium running
- **Service health monitoring** with automatic restart capabilities
- **Integration detection** automatically uses persistent services when available
- **Graceful degradation** falls back to isolated mode when needed

### Performance Analytics
- **Comprehensive timing metrics** for each optimization stage
- **Cache hit/miss reporting** with time savings analysis
- **Performance comparisons** between runs with speedup factors
- **JSON performance reports** for historical analysis

## üìã Key Features

- üì± **Mobile-focused testing**: End-to-end validation of Android APK functionality
- üîÑ **Complete data pipeline**: GPX ‚Üí process_data.py ‚Üí APK ‚Üí Mobile visualization  
- üèóÔ∏è **Isolated environment**: Never touches production data
- üìä **Automated validation**: Map rendering, lasso selection, upload functionality
- ü§ñ **Infrastructure management**: Automatic Appium server and device detection
- ‚ö° **Performance optimization**: Intelligent caching and parallel execution
- üîç **Change detection**: Skip expensive operations when unchanged
- üìà **Performance monitoring**: Detailed metrics and reporting

## Prerequisites

The test framework will check for and help install:
- **Python testing packages**: pytest, appium-python-client, psutil
- **Android tools**: ADB for device communication
- **Node.js**: For Appium server
- **Test data**: Sample GPX files in `test_data/`

## Running Tests

### Basic Commands

```bash
# Run all mobile tests with optimization (recommended)
python run_tests.py

# Fast mode - use cached artifacts, skip builds when possible
python run_tests.py --fast

# Force fresh build - ignore cached artifacts
python run_tests.py --force-build --force-data

# Interactive mode - select specific test
python run_tests.py --one-test

# Performance analysis mode
python run_tests.py --performance-report

# Disable optimizations (traditional mode)
python run_tests.py --no-optimize
```

### Advanced Optimization Commands

```bash
# Reset optimization cache (force full rebuild next run)
python change_detector.py --reset-baseline

# Check what optimizations would be applied
python change_detector.py --analyze

# Parallel execution with custom worker count
MAX_PARALLEL_WORKERS=2 python run_tests.py

# Enable detailed performance metrics
DETAILED_TIMING_METRICS=true python run_tests.py --performance-report
```

### Persistent Infrastructure Workflow

```bash
# Start persistent services
./persist_tests.sh start

# Check service status
./persist_tests.sh status

# Run tests (automatically detects and uses persistent services)
./test.sh

# Run tests multiple times (very fast subsequent runs)
./test.sh
./test.sh

# Restart unhealthy services
./persist_tests.sh restart

# Health check services
./persist_tests.sh health

# Stop persistent services
./persist_tests.sh stop

# Force cleanup all services
./persist_tests.sh cleanup
```

## Test Optimization Modes

### 1. Traditional Mode (--no-optimize)
- Full APK build every run
- Complete data processing every run
- Isolated emulator/Appium startup
- Longest execution time, highest reliability

### 2. Automatic Optimization Mode (default)
- Smart change detection
- Automatic cache utilization
- Parallel execution when safe
- Optimal balance of speed and reliability

### 3. Fast Mode (--fast)
- Requires cached artifacts from previous full build
- Skips all expensive operations
- Fastest execution time
- Best for rapid iteration

### 4. Persistent Infrastructure Mode
- Long-lived emulator and Appium services
- No startup time for subsequent runs
- Service health monitoring
- Best for multiple test cycles

## Performance Metrics & Monitoring

### Timing Breakdown
The framework tracks detailed timing for:
- Emulator startup time
- Appium server startup time  
- APK build time
- Data processing time
- Test execution time
- Parallel vs sequential execution time

### Cache Analytics
- APK build cache hits/misses
- Data processing cache hits/misses
- Optimization effectiveness reporting
- Time savings calculations

### Performance Reports
- JSON format performance data
- Historical performance tracking
- Parallel execution efficiency metrics
- Speedup factor calculations

Example performance output:
```
üìä Performance Summary:
==================================================
   Total execution time: 45.2s
   Emulator startup: 0.0s (cached)
   APK build: 0.0s (cached) 
   Data processing: 0.0s (cached)
   Test execution: 42.1s
   
   Cache performance:
     apk_build: üéØ HIT
     data_processing: üéØ HIT
   
   Optimizations applied: 4
     ‚ö° APK build cache hit
     ‚ö° Data processing cache hit
     ‚ö° Used persistent emulator
     ‚ö° Parallel speedup: 2.1x
```

## What Gets Tested

**Core Mobile Functionality:**
- ‚úÖ APK build process from GPS data
- ‚úÖ Mobile app startup and map rendering
- ‚úÖ Lasso selection and area queries
- ‚úÖ GPX file upload through mobile interface
- ‚úÖ Activity toggling and metadata display
- ‚úÖ Offline operation validation

**Data Processing Pipeline:**
- ‚úÖ GPS file parsing (GPX, FIT, TCX formats)
- ‚úÖ PMTiles generation for offline maps
- ‚úÖ Spatial indexing for fast queries
- ‚úÖ Mobile app data bundling

**Optimization Infrastructure:**
- ‚úÖ Change detection accuracy
- ‚úÖ Cache invalidation correctness
- ‚úÖ Parallel execution safety
- ‚úÖ Service health monitoring
- ‚úÖ Performance metrics collection

## Configuration

### Environment Variables

**Caching Configuration:**
```bash
ENABLE_CACHING=true                     # Enable/disable caching system
CACHE_TTL_HOURS=24                      # Cache validity in hours
AUTO_CACHE_CLEANUP=true                 # Automatic cache cleanup
```

**Parallel Execution:**
```bash
ENABLE_PARALLEL_EXECUTION=true         # Enable parallel test execution
MAX_PARALLEL_WORKERS=4                  # Maximum parallel workers
PARALLEL_TIMEOUT_MULTIPLIER=1.5        # Timeout multiplier for parallel tests
```

**Service Management:**
```bash
EMULATOR_STARTUP_TIMEOUT=180           # Emulator startup timeout (seconds)
APPIUM_STARTUP_TIMEOUT=30              # Appium startup timeout (seconds)
SERVICE_HEALTH_CHECK_TIMEOUT=30       # Health check timeout (seconds)
MAX_SERVICE_RESTART_ATTEMPTS=3        # Maximum restart attempts
```

**Performance Monitoring:**
```bash
ENABLE_PERFORMANCE_MONITORING=true    # Enable performance tracking
PERFORMANCE_REPORT_FORMAT=json        # Report format (json, csv, both)
DETAILED_TIMING_METRICS=true          # Enable detailed timing
```

**Persistent Infrastructure:**
```bash
PERSISTENT_INFRASTRUCTURE_ENABLED=false    # Enable persistent infrastructure
AUTO_START_PERSISTENT_SERVICES=false       # Auto-start services
PERSISTENT_SERVICE_AUTO_RESTART=true       # Auto-restart unhealthy services
```

### Configuration Files

**`config.py`** - Main configuration with optimization settings:
- Test environment settings
- Device capabilities  
- Optimization parameters
- Cache directory locations
- Timeout configurations

**`pytest.ini`** - Pytest configuration with optimization markers:
- Test discovery settings
- Optimization-specific markers
- Performance reporting settings
- Parallel execution markers

## Test Environment

### Device Requirements
- Android device or emulator connected via ADB
- USB debugging enabled
- Sufficient storage for test APK installation

### Test Data
Tests use isolated sample data in `test_data/`:
- `sample_run.gpx` - Basic GPS track for functionality testing
- `eastside_run.gpx` - Complex route for advanced testing
- `manual_upload_run.gpx` - File for upload testing

### Cache Directories
The optimization system creates these cache directories:
- `cached_test_apk/` - Cached APK builds
- `cached_test_data/` - Cached PMTiles data
- `.change_detector_cache/` - Change detection baselines
- `.service_cache/` - Persistent service state
- `.optimization_cache/` - General optimization cache

### Automated Setup
The test framework automatically:
1. Detects connected Android devices
2. Starts Appium server for mobile automation (or uses persistent)
3. Analyzes changes and optimizes build process
4. Builds test APK with sample data (only when needed)
5. Installs and tests the mobile app
6. Executes tests in parallel when safe
7. Generates HTML test reports with performance metrics
8. Cleans up test installations (unless using persistent mode)

## Test Structure

```
testing/
‚îú‚îÄ‚îÄ run_tests.py                  # Main optimized test runner
‚îú‚îÄ‚îÄ test.sh                       # Simple test execution wrapper
‚îú‚îÄ‚îÄ persist_tests.sh              # Persistent infrastructure manager
‚îú‚îÄ‚îÄ change_detector.py            # Intelligent change detection
‚îú‚îÄ‚îÄ service_manager.py            # Service lifecycle management
‚îú‚îÄ‚îÄ test_*.py                     # Individual test modules
‚îú‚îÄ‚îÄ config.py                     # Configuration with optimization settings
‚îú‚îÄ‚îÄ pytest.ini                   # Pytest configuration with markers
‚îú‚îÄ‚îÄ conftest.py                   # Fixtures with caching support
‚îú‚îÄ‚îÄ test_data/                    # Sample GPS files
‚îú‚îÄ‚îÄ reports/                      # HTML test reports with performance data
‚îú‚îÄ‚îÄ cached_test_apk/              # Cached APK builds
‚îú‚îÄ‚îÄ cached_test_data/             # Cached PMTiles data
‚îú‚îÄ‚îÄ .change_detector_cache/       # Change detection baselines
‚îú‚îÄ‚îÄ .service_cache/               # Persistent service state
‚îî‚îÄ‚îÄ .optimization_cache/          # General optimization cache
```

**Key Test Modules:**
- `test_00_infrastructure_setup.py` - Environment validation and optimization testing
- `test_01_activity_visibility.py` - Basic mobile app functionality
- `test_basic_lasso_selection.py` - Area selection testing
- `test_upload_functionality.py` - Mobile file upload testing
- `test_extras_last_activity_filter.py` - Advanced filtering functionality

## Development Workflow

### Adding New Tests

1. Create test file following naming convention: `test_<feature>.py`
2. Use `base_mobile_test.py` as foundation for mobile tests
3. Add appropriate pytest markers for optimization:
   ```python
   @pytest.mark.mobile
   @pytest.mark.parallel_safe  # or parallel_unsafe
   @pytest.mark.cache_dependent  # if requires cached artifacts
   ```
4. Test with multiple optimization modes:
   - `python run_tests.py` (automatic optimization)
   - `python run_tests.py --fast` (cached artifacts)
   - `python run_tests.py --no-optimize` (traditional)

### Test Development Tips

**Performance Considerations:**
- Mark tests as `parallel_safe` when they don't share state
- Use `parallel_unsafe` for tests that modify shared resources
- Consider cache dependencies when designing tests
- Test both optimized and traditional execution paths

**Mobile App Testing:**
- Use page object pattern for mobile UI interactions
- Test offline functionality - no network dependencies
- Validate data persistence between app restarts
- Include both positive and negative test cases

**Optimization Integration:**
- Design tests to work with cached artifacts
- Avoid hard dependencies on fresh builds when possible
- Test optimization edge cases (cache corruption, service failures)
- Verify tests work in persistent infrastructure mode

### Test Markers for Optimization

```python
# Parallel execution safety
@pytest.mark.parallel_safe      # Can run with other tests
@pytest.mark.parallel_unsafe    # Requires sequential execution

# Cache dependencies  
@pytest.mark.cache_dependent    # Relies on cached artifacts
@pytest.mark.build_required     # Requires fresh APK build
@pytest.mark.data_required      # Requires fresh data processing

# Performance testing
@pytest.mark.performance        # Measures optimization effectiveness
@pytest.mark.infrastructure     # Tests service infrastructure
```

### Debugging Tests

```bash
# Run single test interactively with optimization analysis
python run_tests.py --one-test

# Check what optimizations would be applied
python change_detector.py --analyze

# Check persistent service status
./persist_tests.sh status

# View detailed performance breakdown
python run_tests.py --performance-report

# Reset optimization cache for debugging
python change_detector.py --reset-baseline

# Check test reports with performance data
open testing/reports/test_report.html

# View mobile app logs (if device connected)
adb logcat -s chromium AndroidRuntime CapacitorConsole

# Debug service issues
./persist_tests.sh health
```

## Architecture

### Optimization System Flow

1. **Change Detection**: Analyze source and data file modifications
2. **Optimization Analysis**: Determine what operations can be skipped
3. **Service Detection**: Check for persistent infrastructure
4. **Build Optimization**: Skip APK builds when source unchanged
5. **Data Optimization**: Skip data processing when data unchanged
6. **Parallel Orchestration**: Execute tests safely in parallel
7. **Performance Monitoring**: Track metrics and generate reports

### Caching Strategy

**APK Build Cache:**
- Monitors: `server/`, `mobile/`, `package.json`
- Cache location: `cached_test_apk/app-debug.apk`
- Invalidation: Source file modifications detected

**Data Processing Cache:**
- Monitors: `test_data/*.gpx`, `data/raw/`
- Cache location: `cached_test_data/runs.pmtiles`
- Invalidation: Data file modifications detected

**Change Detection Cache:**
- Location: `.change_detector_cache/baseline.json`
- Content: File modification timestamps and metadata
- Updates: After successful builds/processing

### Service Management

**Traditional Mode:**
- Start emulator and Appium for each test run
- Full cleanup after tests complete
- Isolated execution environment

**Persistent Mode:**
- Long-lived emulator and Appium services
- Health monitoring with auto-restart
- Shared across multiple test runs
- Manual lifecycle management via `persist_tests.sh`

### Parallel Execution Strategy

**Dependency Analysis:**
- Analyze test fixture dependencies
- Group tests by shared state requirements
- Identify parallel-safe vs parallel-unsafe tests

**Execution Orchestration:**
- Execute parallel-safe tests concurrently
- Serialize parallel-unsafe tests
- Monitor for conflicts and failures
- Automatic fallback to sequential execution

## Troubleshooting

### Performance Issues

**Tests running slowly:**
```bash
# Check if optimizations are enabled
python change_detector.py --analyze

# Reset cache and rebuild baseline
python change_detector.py --reset-baseline

# Use persistent infrastructure for multiple runs
./persist_tests.sh start

# Check for parallel execution failures
python run_tests.py --performance-report
```

**Cache not working:**
```bash
# Verify cache directories exist and are writable
ls -la cached_test_*/ .change_detector_cache/

# Check cache configuration
grep -i cache config.py

# Reset cache and rebuild
python change_detector.py --reset-baseline
python run_tests.py --force-build --force-data
```

### Service Issues

**Persistent infrastructure problems:**
```bash
# Check service status
./persist_tests.sh status

# Restart unhealthy services
./persist_tests.sh restart

# Full cleanup and restart
./persist_tests.sh stop
./persist_tests.sh start

# Health check with details
./persist_tests.sh health
```

**Emulator/Appium issues:**
```bash
# Check devices
adb devices

# Manual emulator start
emulator -avd YourAVDName

# Check Appium server
npx appium --version

# Reset ADB
adb kill-server && adb start-server
```

### Common Issues

**No Android devices found:**
```bash
# Check device connection
adb devices

# Start emulator manually if needed  
emulator -avd YourAVDName

# Verify USB debugging enabled
```

**APK build failures:**
```bash
# Check prerequisites
python build_mobile.py

# Force fresh build ignoring cache
python run_tests.py --force-build --no-optimize

# Check build logs for errors
```

**Parallel execution failures:**
```bash
# Disable parallel execution temporarily
ENABLE_PARALLEL_EXECUTION=false python run_tests.py

# Reduce worker count
MAX_PARALLEL_WORKERS=1 python run_tests.py

# Check for test conflicts in logs
```

**Cache corruption:**
```bash
# Reset all caches
python change_detector.py --reset-baseline
rm -rf cached_test_* .change_detector_cache/ .service_cache/

# Force full rebuild
python run_tests.py --force-build --force-data --no-optimize
```

### Getting Help

1. **Performance Analysis**: `python run_tests.py --performance-report`
2. **Optimization Status**: `python change_detector.py --analyze`
3. **Service Health**: `./persist_tests.sh health`
4. **Test Reports**: Check `testing/reports/test_report.html`
5. **Infrastructure Test**: `python run_tests.py --one-test` ‚Üí select test_00
6. **Mobile Build Test**: `cd server && python build_mobile.py`
7. **Mobile App Logs**: `adb logcat -s CapacitorConsole`

## Contributing

### When Adding New Mobile Functionality

1. **Add corresponding tests** for the new feature
2. **Test optimization modes**: 
   - `python run_tests.py` (automatic optimization)
   - `python run_tests.py --fast` (cached artifacts)
   - `python run_tests.py --no-optimize` (traditional)
3. **Test persistent infrastructure**: Use `./persist_tests.sh start` workflow
4. **Add appropriate markers** for parallel safety and cache dependencies
5. **Update documentation** if adding new test patterns
6. **Verify performance impact** with `--performance-report`

### Performance Testing

When modifying optimization features:
1. **Benchmark before and after** changes
2. **Test cache invalidation** scenarios
3. **Verify parallel execution** safety
4. **Test service health monitoring** and auto-restart
5. **Validate performance metrics** accuracy

### Code Quality

- Follow existing patterns for change detection and caching
- Maintain backward compatibility with traditional test execution
- Add comprehensive error handling with graceful degradation
- Include performance monitoring for new features
- Test both optimized and fallback code paths

---

## Performance Benefits

The optimization system provides significant performance improvements:

- **Initial build caching**: 5-10 minute APK builds ‚Üí 0 seconds (cache hit)
- **Data processing caching**: 30-60 second processing ‚Üí 0 seconds (cache hit)  
- **Persistent infrastructure**: 2-3 minute service startup ‚Üí 0 seconds (persistent)
- **Parallel execution**: 2-4x speedup for test execution (when safe)
- **Smart dependency tracking**: Only rebuild what actually changed

**Typical performance gains:**
- Full build: ~15 minutes ‚Üí 45 seconds (with cache hits)
- Subsequent runs: ~15 minutes ‚Üí 30 seconds (with persistent infrastructure)
- Development iterations: Near-instant test feedback with comprehensive caching

**Focus**: This optimized testing framework validates the complete mobile GPS visualization experience while maximizing development velocity through intelligent caching, parallel execution, and persistent infrastructure. üì±üó∫Ô∏è‚ö°